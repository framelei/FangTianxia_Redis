2019-08-02 00:32:18 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: fang)
2019-08-02 00:32:18 [scrapy.utils.log] INFO: Versions: lxml 3.7.2.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-10-10.0.17763-SP0
2019-08-02 00:32:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'fang', 'CONCURRENT_REQUESTS': 10, 'DOWNLOAD_DELAY': 0.25, 'DOWNLOAD_TIMEOUT': 10, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_FILE': 'NewHouse20190802.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'fang.spiders', 'RETRY_TIMES': 3, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['fang.spiders']}
2019-08-02 00:32:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-08-02 00:32:19 [fang] INFO: Reading start URLs from redis key 'fangtianxia:start_urls' (batch size: 10, encoding: utf-8
2019-08-02 00:32:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'fang.middlewares.UserAgent',
 'fang.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-08-02 00:32:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-08-02 00:32:19 [scrapy.middleware] INFO: Enabled item pipelines:
['fang.pipelines.MysqlTwistedPipline']
2019-08-02 00:32:19 [scrapy.core.engine] INFO: Spider opened
2019-08-02 00:32:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-08-02 00:33:23 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 21 pages/min), scraped 337 items (at 337 items/min)
2019-08-02 00:34:24 [scrapy.extensions.logstats] INFO: Crawled 40 pages (at 19 pages/min), scraped 555 items (at 218 items/min)
2019-08-02 00:35:22 [scrapy.extensions.logstats] INFO: Crawled 47 pages (at 7 pages/min), scraped 693 items (at 138 items/min)
2019-08-02 00:36:23 [scrapy.extensions.logstats] INFO: Crawled 64 pages (at 17 pages/min), scraped 894 items (at 201 items/min)
2019-08-02 00:37:22 [scrapy.extensions.logstats] INFO: Crawled 75 pages (at 11 pages/min), scraped 1092 items (at 198 items/min)
2019-08-02 00:38:21 [scrapy.extensions.logstats] INFO: Crawled 78 pages (at 3 pages/min), scraped 1294 items (at 202 items/min)
2019-08-02 00:39:21 [scrapy.extensions.logstats] INFO: Crawled 98 pages (at 20 pages/min), scraped 1413 items (at 119 items/min)
2019-08-02 00:40:23 [scrapy.extensions.logstats] INFO: Crawled 107 pages (at 9 pages/min), scraped 1620 items (at 207 items/min)
2019-08-02 00:41:22 [scrapy.extensions.logstats] INFO: Crawled 109 pages (at 2 pages/min), scraped 1825 items (at 205 items/min)
2019-08-02 00:42:23 [scrapy.extensions.logstats] INFO: Crawled 118 pages (at 9 pages/min), scraped 1917 items (at 92 items/min)
2019-08-02 00:43:22 [scrapy.extensions.logstats] INFO: Crawled 120 pages (at 2 pages/min), scraped 1986 items (at 69 items/min)
2019-08-02 00:44:21 [scrapy.extensions.logstats] INFO: Crawled 125 pages (at 5 pages/min), scraped 2085 items (at 99 items/min)
2019-08-02 00:45:21 [scrapy.extensions.logstats] INFO: Crawled 125 pages (at 0 pages/min), scraped 2133 items (at 48 items/min)
2019-08-02 00:46:23 [scrapy.extensions.logstats] INFO: Crawled 141 pages (at 16 pages/min), scraped 2250 items (at 117 items/min)
2019-08-02 00:47:21 [scrapy.extensions.logstats] INFO: Crawled 141 pages (at 0 pages/min), scraped 2370 items (at 120 items/min)
2019-08-02 00:48:21 [scrapy.extensions.logstats] INFO: Crawled 154 pages (at 13 pages/min), scraped 2474 items (at 104 items/min)
2019-08-02 00:49:24 [scrapy.extensions.logstats] INFO: Crawled 160 pages (at 6 pages/min), scraped 2666 items (at 192 items/min)
2019-08-02 00:50:21 [scrapy.extensions.logstats] INFO: Crawled 160 pages (at 0 pages/min), scraped 2778 items (at 112 items/min)
2019-08-02 00:51:23 [scrapy.extensions.logstats] INFO: Crawled 179 pages (at 19 pages/min), scraped 2910 items (at 132 items/min)
2019-08-02 00:52:21 [scrapy.extensions.logstats] INFO: Crawled 179 pages (at 0 pages/min), scraped 3036 items (at 126 items/min)
2019-08-02 00:53:22 [scrapy.extensions.logstats] INFO: Crawled 180 pages (at 1 pages/min), scraped 3091 items (at 55 items/min)
2019-08-02 00:54:22 [scrapy.extensions.logstats] INFO: Crawled 195 pages (at 15 pages/min), scraped 3258 items (at 167 items/min)
2019-08-02 00:55:21 [scrapy.extensions.logstats] INFO: Crawled 198 pages (at 3 pages/min), scraped 3370 items (at 112 items/min)
2019-08-02 00:56:22 [scrapy.extensions.logstats] INFO: Crawled 209 pages (at 11 pages/min), scraped 3527 items (at 157 items/min)
2019-08-02 00:57:22 [scrapy.extensions.logstats] INFO: Crawled 209 pages (at 0 pages/min), scraped 3614 items (at 87 items/min)
2019-08-02 00:58:21 [scrapy.extensions.logstats] INFO: Crawled 219 pages (at 10 pages/min), scraped 3660 items (at 46 items/min)
2019-08-02 00:59:22 [scrapy.extensions.logstats] INFO: Crawled 230 pages (at 11 pages/min), scraped 3861 items (at 201 items/min)
2019-08-02 01:00:21 [scrapy.extensions.logstats] INFO: Crawled 230 pages (at 0 pages/min), scraped 4000 items (at 139 items/min)
2019-08-02 01:01:22 [scrapy.extensions.logstats] INFO: Crawled 248 pages (at 18 pages/min), scraped 4135 items (at 135 items/min)
2019-08-02 01:02:22 [scrapy.extensions.logstats] INFO: Crawled 261 pages (at 13 pages/min), scraped 4416 items (at 281 items/min)
2019-08-02 01:03:21 [scrapy.extensions.logstats] INFO: Crawled 271 pages (at 10 pages/min), scraped 4644 items (at 228 items/min)
2019-08-02 01:04:22 [scrapy.extensions.logstats] INFO: Crawled 282 pages (at 11 pages/min), scraped 4895 items (at 251 items/min)
2019-08-02 01:05:25 [scrapy.extensions.logstats] INFO: Crawled 302 pages (at 20 pages/min), scraped 5246 items (at 351 items/min)
2019-08-02 01:05:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://wuhan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://wuhan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://yichun.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://yichun.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://yili.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://yili.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://anyang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://anyang.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://dazhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://dazhou.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://jizhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://jizhou.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://nongan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://nongan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://xinjin.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://xinjin.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://bayan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://bayan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://yilan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://yilan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://anshun.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://anshun.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://gaoyou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://gaoyou.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://lankao.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://lankao.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://yutian.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://yutian.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://yuxian.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://yuxian.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://wuhai.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://wuhai.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://guoluo.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://guoluo.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:22 [scrapy.extensions.logstats] INFO: Crawled 329 pages (at 27 pages/min), scraped 5648 items (at 402 items/min)
2019-08-02 01:06:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://guyuan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://guyuan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://luzhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://luzhou.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://ningde.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ningde.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://panjin.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://panjin.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://qujing.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://qujing.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://rudong.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://rudong.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://huzhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://huzhou.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://ziyang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ziyang.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://donghai.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-08-02 01:06:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://wenan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://wenan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://hetian.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://hetian.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://ruijin.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ruijin.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://wuzhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://wuzhou.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://zunhua.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://zunhua.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://huairen.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://huairen.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://xinghua.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://xinghua.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:06:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://yichuan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://yichuan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:07:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://baishan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://baishan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:07:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://jinzhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://jinzhou.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:07:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://kaiping.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://kaiping.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:07:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://jining.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://jining.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:07:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://huizhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://huizhou.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:07:23 [scrapy.extensions.logstats] INFO: Crawled 361 pages (at 32 pages/min), scraped 6120 items (at 472 items/min)
2019-08-02 01:07:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://nanping.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://nanping.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:07:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://shannan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://shannan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:07:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://taishan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://taishan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:07:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://wanning.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://wanning.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:07:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://wenling.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://wenling.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:07:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://wenshan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://wenshan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:07:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://xingyang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-08-02 01:07:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://yongning.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://yongning.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:07:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://bazhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://bazhou.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:07:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://dingxi.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://dingxi.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:08:22 [scrapy.extensions.logstats] INFO: Crawled 377 pages (at 16 pages/min), scraped 6542 items (at 422 items/min)
2019-08-02 01:08:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://guilin.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://guilin.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:08:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://ruzhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ruzhou.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:08:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://yangqu.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://yangqu.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:08:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://yanshi.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'ssl handshake failure')]>]
2019-08-02 01:08:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://sxyulin.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://sxyulin.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:08:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://baicheng.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://baicheng.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:08:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://chuxiong.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://chuxiong.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:08:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://heshan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://heshan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:08:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://renqiu.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://renqiu.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:08:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://cqwulong.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-08-02 01:08:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://feicheng.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://feicheng.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:08:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://haicheng.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://haicheng.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:08:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://huaiyuan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://huaiyuan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:08:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://jianyang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-08-02 01:09:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://jinchang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://jinchang.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://xinzheng.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-08-02 01:09:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://yongkang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-08-02 01:09:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://zhaoqing.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://zhaoqing.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://guzhen.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-08-02 01:09:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://zhongwei.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://zhongwei.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:23 [scrapy.extensions.logstats] INFO: Crawled 404 pages (at 27 pages/min), scraped 6909 items (at 367 items/min)
2019-08-02 01:09:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://zhoushan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://zhoushan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://bozhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://bozhou.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://cqdazu.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://cqdazu.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://datong.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://datong.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://gannan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://gannan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://gongyi.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://gongyi.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://leshan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://leshan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://liling.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://liling.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://linhai.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://linhai.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://linxia.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://linxia.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://quzhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://quzhou.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://xintai.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-08-02 01:09:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://yiyang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://yiyang.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://yuhuan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://yuhuan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://jieyang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://jieyang.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://jiuquan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://jiuquan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://suizhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://suizhou.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://yueqing.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://yueqing.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://fanchang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://fanchang.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://pengzhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://pengzhou.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://tongcheng.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://tongcheng.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://heihe.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://heihe.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://binzhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://binzhou.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://chizhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://chizhou.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://huaihua.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-08-02 01:09:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://lianjiang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-08-02 01:09:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://yanbian.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://yanbian.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://baoying.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-08-02 01:09:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://chengde.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://chengde.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://dongtai.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://dongtai.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:09:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://longnan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://longnan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:10:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://sanming.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-08-02 01:10:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://leizhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-08-02 01:10:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://jintan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://jintan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:10:05 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in https://yangquan.newhouse.fang.com/house/s/b92/. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2019-08-02 01:10:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://dandong.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-08-02 01:10:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://danzhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-08-02 01:10:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://jiangdu.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://jiangdu.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:10:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://lijiang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://lijiang.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:10:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://suining.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-08-02 01:10:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://mengjin.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://mengjin.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:10:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://nujiang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://nujiang.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:10:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://jingmen.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-08-02 01:10:21 [scrapy.extensions.logstats] INFO: Crawled 414 pages (at 10 pages/min), scraped 7172 items (at 263 items/min)
2019-08-02 01:10:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://minqing.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-08-02 01:10:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://cqkaixian.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://cqkaixian.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:10:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://jingjiang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://jingjiang.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:10:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://xuancheng.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://xuancheng.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:10:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://changxing.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-08-02 01:10:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://dangyang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-08-02 01:10:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://wenchang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://wenchang.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:10:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://xianning.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://xianning.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:10:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://xianyang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://xianyang.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:10:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://yangchun.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://yangchun.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:10:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://cqshizhu.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://cqshizhu.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:10:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://dengfeng.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://dengfeng.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:10:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://luanxian.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-08-02 01:10:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://yancheng.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://yancheng.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:10:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://haimen.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-08-02 01:10:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://zhucheng.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-08-02 01:10:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://baiyin.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://baiyin.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:10:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://jiaozuo.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://jiaozuo.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:10:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://ahsuzhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ahsuzhou.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:10:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://mianyang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://mianyang.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:10:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://qingyang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-08-02 01:10:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://yongzhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://yongzhou.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://zigong.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://zigong.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://yongchun.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-08-02 01:11:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://dingxing.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://dingxing.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://jinzhong.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://jinzhong.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://yinchuan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://yinchuan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://pingxiang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://pingxiang.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://xinmin.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://xinmin.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://xiuwen.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://xiuwen.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://chongzhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://chongzhou.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:22 [scrapy.extensions.logstats] INFO: Crawled 436 pages (at 22 pages/min), scraped 7478 items (at 306 items/min)
2019-08-02 01:11:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://huanggang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://huanggang.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://tongchuan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://tongchuan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://yongchuan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://yongchuan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://pingtan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-08-02 01:11:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://wuzhong.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-08-02 01:11:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://xuchang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://xuchang.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://yizheng.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-08-02 01:11:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://cqyunyang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://cqyunyang.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://yongcheng.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://yongcheng.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://cqtongnan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://cqtongnan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://dangtu.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://dangtu.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://jiyuan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://jiyuan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://nanyang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://nanyang.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://zhangqiu.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://zhangqiu.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://guangyuan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://guangyuan.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://liaozhong.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-08-02 01:11:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://yongqing.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://yongqing.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://yongdeng.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://yongdeng.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://ningxiang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ningxiang.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://tongxiang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://tongxiang.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://dongxing.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://dongxing.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://donggang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://donggang.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://jiujiang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://jiujiang.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:11:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://fengcheng.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://fengcheng.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:12:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://fengjie.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://fengjie.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:12:21 [scrapy.extensions.logstats] INFO: Crawled 443 pages (at 7 pages/min), scraped 7735 items (at 257 items/min)
2019-08-02 01:13:20 [scrapy.extensions.logstats] INFO: Crawled 453 pages (at 10 pages/min), scraped 7874 items (at 139 items/min)
2019-08-02 01:14:21 [scrapy.extensions.logstats] INFO: Crawled 478 pages (at 25 pages/min), scraped 8315 items (at 441 items/min)
2019-08-02 01:15:21 [scrapy.extensions.logstats] INFO: Crawled 506 pages (at 28 pages/min), scraped 8806 items (at 491 items/min)
2019-08-02 01:16:11 [scrapy.core.scraper] ERROR: Error downloading <GET http://yixing.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:13 [scrapy.core.scraper] ERROR: Error downloading <GET http://xiantao.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:13 [scrapy.core.scraper] ERROR: Error downloading <GET http://leiyang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://gaoling.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:15 [scrapy.core.scraper] ERROR: Error downloading <GET http://xinzhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://chenzhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://laizhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://linzhi.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://neijiang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://jxfuzhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://changshu.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://qingzhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://liyang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:21 [scrapy.extensions.logstats] INFO: Crawled 526 pages (at 20 pages/min), scraped 9240 items (at 434 items/min)
2019-08-02 01:16:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://qingyuan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:24 [scrapy.core.scraper] ERROR: Error downloading <GET http://quanjiao.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:24 [scrapy.core.scraper] ERROR: Error downloading <GET http://qingzhen.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:25 [scrapy.core.scraper] ERROR: Error downloading <GET http://anda.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:25 [scrapy.core.scraper] ERROR: Error downloading <GET http://liangshan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:25 [scrapy.core.scraper] ERROR: Error downloading <GET http://rikaze.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:25 [scrapy.core.scraper] ERROR: Error downloading <GET http://kuitun.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:27 [scrapy.core.scraper] ERROR: Error downloading <GET http://chaoyang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:27 [scrapy.core.scraper] ERROR: Error downloading <GET http://changchun.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:27 [scrapy.core.scraper] ERROR: Error downloading <GET http://ganzhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://laibin.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:30 [scrapy.core.scraper] ERROR: Error downloading <GET http://xiaogan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:30 [scrapy.core.scraper] ERROR: Error downloading <GET http://lantian.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:30 [scrapy.core.scraper] ERROR: Error downloading <GET http://xinyang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:30 [scrapy.core.scraper] ERROR: Error downloading <GET http://dingzhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:30 [scrapy.core.scraper] ERROR: Error downloading <GET http://fenghua.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:31 [scrapy.core.scraper] ERROR: Error downloading <GET http://lincang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:31 [scrapy.core.scraper] ERROR: Error downloading <GET http://laiyang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:31 [scrapy.core.scraper] ERROR: Error downloading <GET http://kaiyang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:31 [scrapy.core.scraper] ERROR: Error downloading <GET http://liaoyang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://xiangxi.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:34 [scrapy.core.scraper] ERROR: Error downloading <GET http://liuzhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:34 [scrapy.core.scraper] ERROR: Error downloading <GET http://liuyang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:34 [scrapy.core.scraper] ERROR: Error downloading <GET http://gaoyang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://ninghai.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://changzhi.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://xingtai.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://liaoyuan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://dengzhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://quanshan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://cangzhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://quangang.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://chongzuo.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://qionghai.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://nanchong.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:37 [scrapy.core.scraper] ERROR: Error downloading <GET http://qionglai.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:37 [scrapy.core.scraper] ERROR: Error downloading <GET http://shangluo.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:37 [scrapy.core.scraper] ERROR: Error downloading <GET http://wj.esf.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:37 [scrapy.core.scraper] ERROR: Error downloading <GET http://chaozhou.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:38 [scrapy.core.scraper] ERROR: Error downloading <GET http://xinjian.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:38 [scrapy.core.scraper] ERROR: Error downloading <GET http://huangshan.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:38 [scrapy.core.scraper] ERROR: Error downloading <GET http://kangping.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:39 [scrapy.core.scraper] ERROR: Error downloading <GET http://laishui.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:40 [scrapy.core.scraper] ERROR: Error downloading <GET http://suihua.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://suihua.newhouse.fang.com/house/s/b91/ took longer than 10.0 seconds..
2019-08-02 01:16:42 [scrapy.core.scraper] ERROR: Error downloading <GET http://esf.changji.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:16:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://qianan.newhouse.fang.com/house/s/b92/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://qianan.newhouse.fang.com/house/s/b92/ took longer than 10.0 seconds..
2019-08-02 01:16:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://weinan.newhouse.fang.com/house/s/b95/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://weinan.newhouse.fang.com/house/s/b95/ took longer than 10.0 seconds..
2019-08-02 01:16:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://heyuan.newhouse.fang.com/house/s/b93/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://heyuan.newhouse.fang.com/house/s/b93/ took longer than 10.0 seconds..
2019-08-02 01:16:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://suzhou.newhouse.fang.com/house/s/b911/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://suzhou.newhouse.fang.com/house/s/b911/ took longer than 10.0 seconds..
2019-08-02 01:17:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://baoshan.newhouse.fang.com/house/s/b93/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://baoshan.newhouse.fang.com/house/s/b93/ took longer than 10.0 seconds..
2019-08-02 01:17:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://tieling.newhouse.fang.com/house/s/b92/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://tieling.newhouse.fang.com/house/s/b92/ took longer than 10.0 seconds..
2019-08-02 01:17:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://zhuzhou.newhouse.fang.com/house/s/b910/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://zhuzhou.newhouse.fang.com/house/s/b910/ took longer than 10.0 seconds..
2019-08-02 01:17:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://taixing.newhouse.fang.com/house/s/b93/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://taixing.newhouse.fang.com/house/s/b93/ took longer than 10.0 seconds..
2019-08-02 01:17:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://zhuzhou.newhouse.fang.com/house/s/b97/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://zhuzhou.newhouse.fang.com/house/s/b97/ took longer than 10.0 seconds..
2019-08-02 01:17:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://taizhou.newhouse.fang.com/house/s/b911/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://taizhou.newhouse.fang.com/house/s/b911/ took longer than 10.0 seconds..
2019-08-02 01:17:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://shanwei.newhouse.fang.com/house/s/b92/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://shanwei.newhouse.fang.com/house/s/b92/ took longer than 10.0 seconds..
2019-08-02 01:17:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://tianmen.newhouse.fang.com/house/s/b92/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://tianmen.newhouse.fang.com/house/s/b92/ took longer than 10.0 seconds..
2019-08-02 01:17:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://kuerle.newhouse.fang.com/house/s/b94/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://kuerle.newhouse.fang.com/house/s/b94/ took longer than 10.0 seconds..
2019-08-02 01:17:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://weinan.newhouse.fang.com/house/s/b96/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://weinan.newhouse.fang.com/house/s/b96/ took longer than 10.0 seconds..
2019-08-02 01:17:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://haining.newhouse.fang.com/house/s/b93/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://haining.newhouse.fang.com/house/s/b93/ took longer than 10.0 seconds..
2019-08-02 01:17:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://suzhou.newhouse.fang.com/house/s/b915/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://suzhou.newhouse.fang.com/house/s/b915/ took longer than 10.0 seconds..
2019-08-02 01:17:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://deyang.newhouse.fang.com/house/s/b95/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://deyang.newhouse.fang.com/house/s/b95/ took longer than 10.0 seconds..
2019-08-02 01:17:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://enping.newhouse.fang.com/house/s/b92/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://enping.newhouse.fang.com/house/s/b92/ took longer than 10.0 seconds..
2019-08-02 01:17:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://heyuan.newhouse.fang.com/house/s/b92/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://heyuan.newhouse.fang.com/house/s/b92/ took longer than 10.0 seconds..
2019-08-02 01:17:21 [scrapy.extensions.logstats] INFO: Crawled 549 pages (at 23 pages/min), scraped 9675 items (at 435 items/min)
2019-08-02 01:17:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://huaian.newhouse.fang.com/house/s/b97/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://huaian.newhouse.fang.com/house/s/b97/ took longer than 10.0 seconds..
2019-08-02 01:17:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://qidong.newhouse.fang.com/house/s/b93/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://qidong.newhouse.fang.com/house/s/b93/ took longer than 10.0 seconds..
2019-08-02 01:17:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://changli.newhouse.fang.com/house/s/b92/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://changli.newhouse.fang.com/house/s/b92/ took longer than 10.0 seconds..
2019-08-02 01:17:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://suzhou.newhouse.fang.com/house/s/b916/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://suzhou.newhouse.fang.com/house/s/b916/ took longer than 10.0 seconds..
2019-08-02 01:17:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://shangrao.newhouse.fang.com/house/s/b93/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://shangrao.newhouse.fang.com/house/s/b93/ took longer than 10.0 seconds..
2019-08-02 01:17:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://suzhou.newhouse.fang.com/house/s/b93/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://suzhou.newhouse.fang.com/house/s/b93/ took longer than 10.0 seconds..
2019-08-02 01:17:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://taizhou.newhouse.fang.com/house/s/b98/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://taizhou.newhouse.fang.com/house/s/b98/ took longer than 10.0 seconds..
2019-08-02 01:17:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://meizhou.newhouse.fang.com/house/s/b94/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://meizhou.newhouse.fang.com/house/s/b94/ took longer than 10.0 seconds..
2019-08-02 01:17:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://zhangzhou.newhouse.fang.com/house/s/b97/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://zhangzhou.newhouse.fang.com/house/s/b97/ took longer than 10.0 seconds..
2019-08-02 01:17:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://taizhou.newhouse.fang.com/house/s/b93/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://taizhou.newhouse.fang.com/house/s/b93/ took longer than 10.0 seconds..
2019-08-02 01:17:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://guangrao.newhouse.fang.com/house/s/b93/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://guangrao.newhouse.fang.com/house/s/b93/ took longer than 10.0 seconds..
2019-08-02 01:17:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://songyuan.newhouse.fang.com/house/s/b92/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://songyuan.newhouse.fang.com/house/s/b92/ took longer than 10.0 seconds..
2019-08-02 01:17:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://suzhou.newhouse.fang.com/house/s/b98/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://suzhou.newhouse.fang.com/house/s/b98/ took longer than 10.0 seconds..
2019-08-02 01:17:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://weihai.newhouse.fang.com/house/s/b99/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://weihai.newhouse.fang.com/house/s/b99/ took longer than 10.0 seconds..
2019-08-02 01:17:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://shaoguan.newhouse.fang.com/house/s/b93/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://shaoguan.newhouse.fang.com/house/s/b93/ took longer than 10.0 seconds..
2019-08-02 01:17:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://meishan.newhouse.fang.com/house/s/b92/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://meishan.newhouse.fang.com/house/s/b92/ took longer than 10.0 seconds..
2019-08-02 01:17:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://weihai.newhouse.fang.com/house/s/b92/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://weihai.newhouse.fang.com/house/s/b92/ took longer than 10.0 seconds..
2019-08-02 01:17:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://meizhou.newhouse.fang.com/house/s/b95/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://meizhou.newhouse.fang.com/house/s/b95/ took longer than 10.0 seconds..
2019-08-02 01:18:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://shaoguan.newhouse.fang.com/house/s/b94/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://shaoguan.newhouse.fang.com/house/s/b94/ took longer than 10.0 seconds..
2019-08-02 01:18:02 [scrapy.core.scraper] ERROR: Error downloading <GET http://jixi.newhouse.fang.com/house/s/b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 01:18:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://weihai.newhouse.fang.com/house/s/b98/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://weihai.newhouse.fang.com/house/s/b98/ took longer than 10.0 seconds..
2019-08-02 01:18:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://tongren.newhouse.fang.com/house/s/b92/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://tongren.newhouse.fang.com/house/s/b92/ took longer than 10.0 seconds..
2019-08-02 01:18:20 [scrapy.extensions.logstats] INFO: Crawled 572 pages (at 23 pages/min), scraped 10154 items (at 479 items/min)
2019-08-02 01:19:20 [scrapy.extensions.logstats] INFO: Crawled 572 pages (at 0 pages/min), scraped 10154 items (at 0 items/min)
2019-08-02 01:20:20 [scrapy.extensions.logstats] INFO: Crawled 572 pages (at 0 pages/min), scraped 10154 items (at 0 items/min)
2019-08-02 01:21:20 [scrapy.extensions.logstats] INFO: Crawled 572 pages (at 0 pages/min), scraped 10154 items (at 0 items/min)
2019-08-02 01:22:20 [scrapy.extensions.logstats] INFO: Crawled 572 pages (at 0 pages/min), scraped 10154 items (at 0 items/min)
2019-08-02 01:23:20 [scrapy.extensions.logstats] INFO: Crawled 572 pages (at 0 pages/min), scraped 10154 items (at 0 items/min)
2019-08-02 01:24:20 [scrapy.extensions.logstats] INFO: Crawled 572 pages (at 0 pages/min), scraped 10154 items (at 0 items/min)
2019-08-02 01:25:20 [scrapy.extensions.logstats] INFO: Crawled 572 pages (at 0 pages/min), scraped 10154 items (at 0 items/min)
2019-08-02 01:26:20 [scrapy.extensions.logstats] INFO: Crawled 572 pages (at 0 pages/min), scraped 10154 items (at 0 items/min)
2019-08-02 01:27:20 [scrapy.extensions.logstats] INFO: Crawled 572 pages (at 0 pages/min), scraped 10154 items (at 0 items/min)
2019-08-02 09:42:38 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: fang)
2019-08-02 09:42:38 [scrapy.utils.log] INFO: Versions: lxml 3.7.2.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-10-10.0.17763-SP0
2019-08-02 09:42:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'fang', 'DOWNLOAD_DELAY': 0.1, 'DOWNLOAD_TIMEOUT': 10, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_FILE': 'NewHouse20190802.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'fang.spiders', 'RETRY_TIMES': 3, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['fang.spiders']}
2019-08-02 09:42:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-08-02 09:42:38 [fang] INFO: Reading start URLs from redis key 'fangtianxia:start_urls' (batch size: 16, encoding: utf-8
2019-08-02 09:42:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'fang.middlewares.UserAgent',
 'fang.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-08-02 09:42:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-08-02 09:42:39 [scrapy.middleware] INFO: Enabled item pipelines:
['fang.pipelines.MysqlTwistedPipline']
2019-08-02 09:42:39 [scrapy.core.engine] INFO: Spider opened
2019-08-02 09:42:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-08-02 09:43:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-08-02 09:44:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-08-02 09:45:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://newhouse.fang.com/house/s/b1saledate-b91/> (referer: https://www.fang.com/SoufunFamily.htm)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-28'
2019-08-02 09:45:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://tj.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-37'
2019-08-02 09:45:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-34'
2019-08-02 09:45:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://cq.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-61'
2019-08-02 09:45:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hf.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-29'
2019-08-02 09:45:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://wuhu.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-6'
2019-08-02 09:45:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bengbu.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:45:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://huainan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:45:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://fuyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-10'
2019-08-02 09:45:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://anqing.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:45:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://chaohu.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:45:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://chuzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:45:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://luan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:45:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://tongling.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:45:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://huaibei.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:45:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xuancheng.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:45:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://huangshan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:45:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://ahsuzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-9'
2019-08-02 09:45:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mas.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:45:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://chizhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:45:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bozhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-6'
2019-08-02 09:45:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://tongcheng.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:45:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://feixi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:45:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://feidong.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:45:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://huoqiu.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:45:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://lujiang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:45:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://dangtu.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:45:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://ahcf.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:45:40 [scrapy.extensions.logstats] INFO: Crawled 37 pages (at 37 pages/min), scraped 70 items (at 70 items/min)
2019-08-02 09:45:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://fuling.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:45:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://quanjiao.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:45:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hechuan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:45:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yongchuan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:45:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://cqtongnan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:45:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jiangjin.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:45:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://tongliang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:45:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://dazu.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:45:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://changshou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:45:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bishan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:45:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://fz.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-20'
2019-08-02 09:45:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xm.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-10'
2019-08-02 09:45:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://qz.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-23'
2019-08-02 09:46:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://putian.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:46:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://longyan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:46:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://ningde.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:46:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://fq.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:46:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://changle.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:46:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://huian.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:46:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pingtan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:46:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nanan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:46:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shishi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:46:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nanping.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-6'
2019-08-02 09:46:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://longhai.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:46:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://fjax.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:46:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sanming.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:46:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://gz.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-29'
2019-08-02 09:46:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://dg.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-13'
2019-08-02 09:46:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://fs.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-18'
2019-08-02 09:46:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zs.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-12'
2019-08-02 09:46:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jm.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-17'
2019-08-02 09:46:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zh.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-10'
2019-08-02 09:46:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://st.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-12'
2019-08-02 09:46:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://ya.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:46:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sz.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-20'
2019-08-02 09:46:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zhaoqing.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-11'
2019-08-02 09:46:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://qingyuan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-10'
2019-08-02 09:46:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://huizhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-16'
2019-08-02 09:46:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://maoming.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:46:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zj.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-10'
2019-08-02 09:46:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://heyuan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-6'
2019-08-02 09:46:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://meizhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:46:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://kaiping.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:46:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yunfu.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-6'
2019-08-02 09:46:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shunde.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:46:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://chaozhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:46:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://enping.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:46:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shaoguan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-6'
2019-08-02 09:46:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shanwei.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:46:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://taishan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:46:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yangchun.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:46:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jieyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:46:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://boluo.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:46:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yl.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:46:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://guilin.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-8'
2019-08-02 09:46:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nn.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-15'
2019-08-02 09:46:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://huidong.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:46:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://guigang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-6'
2019-08-02 09:46:40 [scrapy.extensions.logstats] INFO: Crawled 123 pages (at 86 pages/min), scraped 255 items (at 185 items/min)
2019-08-02 09:46:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bh.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-9'
2019-08-02 09:46:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hechi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:46:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://liuzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:46:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://baise.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:46:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://heshan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:46:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hezhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:46:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://qinzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:46:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://puning.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:46:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://wuzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:46:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://chongzuo.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:46:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://laibin.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-6'
2019-08-02 09:46:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://gy.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-12'
2019-08-02 09:46:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zunyi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-8'
2019-08-02 09:46:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://anshun.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:46:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://qiannan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:46:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://dongxing.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:46:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zhangzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-12'
2019-08-02 09:46:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yangjiang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:46:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bijie.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-9'
2019-08-02 09:46:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://tongren.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:46:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://lianjiang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:47:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://baiyin.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:47:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://lz.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-14'
2019-08-02 09:47:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://tianshui.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:47:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jiuquan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:47:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://qingyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:47:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://dingxi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:47:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pingliang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:47:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://wuwei.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:47:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hn.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-35'
2019-08-02 09:47:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://qdn.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:47:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zz.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-45'
2019-08-02 09:47:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sanya.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-11'
2019-08-02 09:47:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://ly.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-17'
2019-08-02 09:47:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zhangye.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:47:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://wanning.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:47:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jiaozuo.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:47:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xx.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-6'
2019-08-02 09:47:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yuzhong.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:47:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://danzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:47:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nanyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:47:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xinyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-6'
2019-08-02 09:47:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://anyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-8'
2019-08-02 09:47:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://puyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-6'
2019-08-02 09:47:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://luohe.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:47:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://gongyi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:47:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://kaifeng.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-10'
2019-08-02 09:47:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://ruzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:47:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hnyz.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:47:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hebi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:47:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xuchang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-10'
2019-08-02 09:47:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zhoukou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:47:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://changge.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:47:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jiyuan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:47:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xinmi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:47:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hnxa.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:47:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hnyy.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:47:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shangqiu.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-10'
2019-08-02 09:47:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mengjin.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:47:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://lankao.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:47:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xingyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:47:40 [scrapy.extensions.logstats] INFO: Crawled 197 pages (at 74 pages/min), scraped 467 items (at 212 items/min)
2019-08-02 09:47:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xinzheng.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-8'
2019-08-02 09:47:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://dengzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:47:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jixi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:47:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yongdeng.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:47:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zhongmou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:47:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daqing.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:47:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hrb.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-11'
2019-08-02 09:47:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yongcheng.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:47:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://suihua.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-6'
2019-08-02 09:47:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://heihe.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:47:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://qianxinan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:47:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://anda.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:47:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yc.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-10'
2019-08-02 09:47:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://wuhan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-34'
2019-08-02 09:48:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xiangyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-6'
2019-08-02 09:48:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jingzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:48:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sanmenxia.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:48:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shiyan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-6'
2019-08-02 09:48:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jingmen.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-6'
2019-08-02 09:48:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://enshi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:48:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://huanggang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:48:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://suizhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:48:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xiaogan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-6'
2019-08-02 09:48:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://ezhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:48:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xianning.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:48:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yidu.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:48:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://huangshi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:48:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zhumadian.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:48:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xiantao.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:48:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://qj.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:48:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jiamusi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:48:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zhongxiang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:48:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://cs.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-34'
2019-08-02 09:48:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xt.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-9'
2019-08-02 09:48:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yueyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:48:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://loudi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:48:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://changde.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-8'
2019-08-02 09:48:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yiyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-6'
2019-08-02 09:48:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://chenzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:48:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://huaihua.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:48:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zhuzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-11'
2019-08-02 09:48:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hengyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-11'
2019-08-02 09:48:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xiangxi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:48:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shaoyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-8'
2019-08-02 09:48:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://ts.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-16'
2019-08-02 09:48:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bd.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-15'
2019-08-02 09:48:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sjz.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-17'
2019-08-02 09:48:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xiangxiang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:48:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yongzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-9'
2019-08-02 09:48:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://lf.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-14'
2019-08-02 09:48:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://ningxiang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:48:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xingtai.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:48:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://cangzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-9'
2019-08-02 09:48:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hd.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-9'
2019-08-02 09:48:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hs.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:48:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://cswc.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:48:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://liuyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:48:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://guan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:48:40 [scrapy.extensions.logstats] INFO: Crawled 287 pages (at 90 pages/min), scraped 798 items (at 331 items/min)
2019-08-02 09:48:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xinji.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:48:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://qianan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:48:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://qhd.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-9'
2019-08-02 09:48:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://dingzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:48:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zhuozhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:48:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://chengde.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-9'
2019-08-02 09:48:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://gaobeidian.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:48:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hbbz.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:48:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://changli.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:48:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zhangjiajie.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:48:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hbsh.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:49:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yz.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-13'
2019-08-02 09:49:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xz.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-20'
2019-08-02 09:49:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://huaian.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-13'
2019-08-02 09:49:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://wuxi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-25'
2019-08-02 09:49:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://suzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-30'
2019-08-02 09:49:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://lyg.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:49:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nanjing.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-24'
2019-08-02 09:49:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yancheng.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-11'
2019-08-02 09:49:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://taizhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-13'
2019-08-02 09:49:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sq.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-10'
2019-08-02 09:49:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yongqing.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:49:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://cz.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-12'
2019-08-02 09:49:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://ks.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-10'
2019-08-02 09:49:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zjg.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:49:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://qidong.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:49:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://liyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:49:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://rugao.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:49:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pizhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:49:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://haimen.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:49:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://taixing.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:49:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xinyi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:49:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xinghua.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:49:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jiangdu.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:49:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://changshu.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:49:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://gaoyou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:49:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://dongtai.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:49:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jy.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-8'
2019-08-02 09:49:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://tc.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:49:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yixing.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:49:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://rudong.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:49:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://haian.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:49:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jintan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:49:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shuyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:49:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yizheng.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:49:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jsfx.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:49:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nc.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-17'
2019-08-02 09:49:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://njgc.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:49:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://quanshan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:49:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xuyi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:49:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jian.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:49:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://tongshan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:49:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yichun.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:49:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xinyu.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:49:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jr.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-6'
2019-08-02 09:49:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://baoying.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:49:40 [scrapy.extensions.logstats] INFO: Crawled 361 pages (at 74 pages/min), scraped 1100 items (at 302 items/min)
2019-08-02 09:49:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jxfc.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:49:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://siping.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:49:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jl.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:49:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://baishan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:49:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://ganzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-9'
2019-08-02 09:49:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xinjian.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:49:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://dehui.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:49:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://dl.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-18'
2019-08-02 09:49:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nongan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:49:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sy.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-24'
2019-08-02 09:49:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://fushun.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:49:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://anshan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:49:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jinzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:49:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yingtan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:49:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yanbian.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:49:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://fuxin.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:49:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yk.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-12'
2019-08-02 09:49:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://benxi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:49:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://tieling.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:50:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://chaoyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-10'
2019-08-02 09:50:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://panjin.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:50:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://dandong.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:50:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jiujiang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-8'
2019-08-02 09:50:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jxfuzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:50:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://liaoyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:50:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jiangyan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:50:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shangrao.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:50:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yinchuan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-11'
2019-08-02 09:50:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://songyuan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:50:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://guyuan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:50:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bt.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:50:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://changchun.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-16'
2019-08-02 09:50:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pingxiang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:50:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://tl.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:50:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://chifeng.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:50:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://huludao.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-8'
2019-08-02 09:50:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zhenjiang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-14'
2019-08-02 09:50:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nm.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-11'
2019-08-02 09:50:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://wuhai.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:50:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pulandian.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:50:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xam.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:50:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xn.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:50:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jn.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-26'
2019-08-02 09:50:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zb.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-10'
2019-08-02 09:50:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://wf.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-28'
2019-08-02 09:50:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://byne.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:50:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://qd.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-41'
2019-08-02 09:50:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://erds.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:50:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yt.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-32'
2019-08-02 09:50:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://dy.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-13'
2019-08-02 09:50:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://linyi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-8'
2019-08-02 09:50:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://lc.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:50:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://dz.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:50:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jining.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-10'
2019-08-02 09:50:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://rz.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:50:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://taian.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-12'
2019-08-02 09:50:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://heze.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-9'
2019-08-02 09:50:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://gaomi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:50:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zhangqiu.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:50:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://binzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:50:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weihai.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-10'
2019-08-02 09:50:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zy.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:50:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zaozhuang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:50:40 [scrapy.extensions.logstats] INFO: Crawled 452 pages (at 91 pages/min), scraped 1388 items (at 288 items/min)
2019-08-02 09:50:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sg.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:50:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xintai.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:50:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://laizhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:50:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://longkou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:50:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://changyi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:50:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://qingzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:50:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://wlcb.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-6'
2019-08-02 09:50:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://anqiu.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:50:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://tengzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:50:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://feicheng.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:50:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hlbe.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:50:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zoucheng.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:50:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://linqu.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:50:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://guangrao.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:50:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://qixia.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:50:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jncq.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:50:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sdjy.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:50:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://laiyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:50:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://linfen.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:50:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://datong.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:50:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://haiyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:51:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://lvliang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:51:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://taiyuan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-20'
2019-08-02 09:51:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jinzhong.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:51:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jc.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:51:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://changzhi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:51:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sxly.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:51:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xian.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-42'
2019-08-02 09:51:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://baoji.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:51:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weinan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-9'
2019-08-02 09:51:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://ankang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:51:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sxyulin.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:51:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hanzhong.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:51:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yanan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:51:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xianyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-9'
2019-08-02 09:51:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://lantian.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:51:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://gaoling.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:51:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shangluo.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:51:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yuncheng.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-6'
2019-08-02 09:51:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yangquan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:51:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://tongchuan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:51:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://deyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-8'
2019-08-02 09:51:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://cd.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-51'
2019-08-02 09:51:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://leshan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:51:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://dazhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:51:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://guangan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-6'
2019-08-02 09:51:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://luzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:51:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bazhong.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:51:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://suining.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:51:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mianyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-9'
2019-08-02 09:51:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://neijiang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:51:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nanchong.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:51:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://panzhihua.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:51:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yibin.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:51:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://guangyuan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:51:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://meishan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-6'
2019-08-02 09:51:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yaan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:51:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://scjt.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:51:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pengzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:51:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jianyang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:51:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://liangshan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:51:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://dayi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:51:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hailaer.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:51:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://qionglai.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:51:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://dujiangyan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:51:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://chongzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:51:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://emeishan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:51:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xinjin.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:51:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://kashi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:51:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://bazhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-6'
2019-08-02 09:51:40 [scrapy.extensions.logstats] INFO: Crawled 537 pages (at 85 pages/min), scraped 1629 items (at 241 items/min)
2019-08-02 09:51:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jizhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:51:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yili.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:51:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xj.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-9'
2019-08-02 09:51:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jingdezhen.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:51:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://kuerle.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:51:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://km.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-18'
2019-08-02 09:51:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://wenshan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:51:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://qujing.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:51:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yuxi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:52:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://lijiang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:52:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://dali.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:52:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://dehong.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:52:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://baoshan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:52:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://puer.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:52:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zhaotong.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:52:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://anning.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:52:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hz.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-27'
2019-08-02 09:52:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nb.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-24'
2019-08-02 09:52:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jx.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-14'
2019-08-02 09:52:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://tz.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-17'
2019-08-02 09:52:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jh.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:52:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sx.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-14'
2019-08-02 09:52:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://wz.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-15'
2019-08-02 09:52:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://ls.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:52:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://quzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:52:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://huzhou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-18'
2019-08-02 09:52:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zhoushan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:52:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://changxing.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:52:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://deqing.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:52:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://cixi.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:52:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://haining.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:52:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zhangjiakou.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-15'
2019-08-02 09:52:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://wenling.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:52:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zhuji.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:52:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yuyao.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:52:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://linhai.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:52:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shangyu.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:52:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pinghu.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:52:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://yuhuan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:52:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zjxs.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:52:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zhenhai.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:52:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://haiyan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-5'
2019-08-02 09:52:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mudanjiang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:52:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://qiqihaer.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:52:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://tongxiang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:52:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://ninghai.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:52:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://pingdingshan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 09:52:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://fenghua.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:52:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nt.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-20'
2019-08-02 09:52:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://peixian.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:52:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jssn.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:52:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://wj.esf.newhouse.fang.com/house/s/b1saledate-b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 09:52:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://wuzhong.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-4'
2019-08-02 09:52:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://esf.changji.newhouse.fang.com/house/s/b1saledate-b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]
2019-08-02 09:52:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://tianmen.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:52:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://xishuangbanna.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:52:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://jingjiang.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-2'
2019-08-02 09:52:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://akesu.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-3'
2019-08-02 09:52:39 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <502 https://ziyang.newhouse.fang.com/house/s/b1saledate-b91/>: HTTP status code is not handled or not allowed
2019-08-02 09:52:39 [scrapy.extensions.logstats] INFO: Crawled 628 pages (at 91 pages/min), scraped 1970 items (at 341 items/min)
2019-08-02 09:52:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://qingzhen.newhouse.fang.com/house/s/b1saledate-b91/>
Traceback (most recent call last):
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\python3.6\anaconda3\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\python3.6\anaconda3\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://qingzhen.newhouse.fang.com/house/s/b1saledate-b91/ took longer than 10.0 seconds..
2019-08-02 09:53:39 [scrapy.extensions.logstats] INFO: Crawled 629 pages (at 1 pages/min), scraped 1976 items (at 6 items/min)
2019-08-02 09:54:39 [scrapy.extensions.logstats] INFO: Crawled 629 pages (at 0 pages/min), scraped 1976 items (at 0 items/min)
2019-08-02 09:55:39 [scrapy.extensions.logstats] INFO: Crawled 629 pages (at 0 pages/min), scraped 1976 items (at 0 items/min)
2019-08-02 09:56:39 [scrapy.extensions.logstats] INFO: Crawled 629 pages (at 0 pages/min), scraped 1976 items (at 0 items/min)
2019-08-02 09:57:39 [scrapy.extensions.logstats] INFO: Crawled 629 pages (at 0 pages/min), scraped 1976 items (at 0 items/min)
2019-08-02 09:58:39 [scrapy.extensions.logstats] INFO: Crawled 629 pages (at 0 pages/min), scraped 1976 items (at 0 items/min)
2019-08-02 09:59:39 [scrapy.extensions.logstats] INFO: Crawled 629 pages (at 0 pages/min), scraped 1976 items (at 0 items/min)
2019-08-02 10:00:39 [scrapy.extensions.logstats] INFO: Crawled 629 pages (at 0 pages/min), scraped 1976 items (at 0 items/min)
2019-08-02 10:01:39 [scrapy.extensions.logstats] INFO: Crawled 629 pages (at 0 pages/min), scraped 1976 items (at 0 items/min)
2019-08-02 10:02:39 [scrapy.extensions.logstats] INFO: Crawled 629 pages (at 0 pages/min), scraped 1976 items (at 0 items/min)
2019-08-02 10:03:39 [scrapy.extensions.logstats] INFO: Crawled 630 pages (at 1 pages/min), scraped 1976 items (at 0 items/min)
2019-08-02 10:04:39 [scrapy.extensions.logstats] INFO: Crawled 630 pages (at 0 pages/min), scraped 1976 items (at 0 items/min)
2019-08-02 10:05:25 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2019-08-02 10:05:25 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-08-02 10:05:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 35,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 1,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 2,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 24,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 8,
 'downloader/request_bytes': 572690,
 'downloader/request_count': 1322,
 'downloader/request_method_count/GET': 1322,
 'downloader/response_bytes': 19293539,
 'downloader/response_count': 1287,
 'downloader/response_status_count/200': 629,
 'downloader/response_status_count/301': 653,
 'downloader/response_status_count/302': 1,
 'downloader/response_status_count/502': 4,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2019, 8, 2, 2, 5, 25, 607735),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/502': 1,
 'item_scraped_count': 1976,
 'log_count/ERROR': 453,
 'log_count/INFO': 32,
 'offsite/filtered': 6,
 'request_depth_max': 1,
 'response_received_count': 630,
 'retry/count': 35,
 'retry/max_reached': 4,
 'retry/reason_count/502 Bad Gateway': 3,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'retry/reason_count/twisted.internet.error.TimeoutError': 23,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 6,
 'scheduler/dequeued/redis': 1322,
 'scheduler/enqueued/redis': 1322,
 'spider_exceptions/ValueError': 450,
 'start_time': datetime.datetime(2019, 8, 2, 1, 42, 39, 871626)}
2019-08-02 10:05:25 [scrapy.core.engine] INFO: Spider closed (shutdown)
2019-08-02 10:08:33 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: fang)
2019-08-02 10:08:33 [scrapy.utils.log] INFO: Versions: lxml 3.7.2.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-10-10.0.17763-SP0
2019-08-02 10:08:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'fang', 'DOWNLOAD_DELAY': 0.1, 'DOWNLOAD_TIMEOUT': 10, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_FILE': 'NewHouse20190802.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'fang.spiders', 'RETRY_TIMES': 3, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['fang.spiders']}
2019-08-02 10:08:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-08-02 10:08:33 [fang] INFO: Reading start URLs from redis key 'fangtianxia:start_urls' (batch size: 16, encoding: utf-8
2019-08-02 10:08:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'fang.middlewares.UserAgent',
 'fang.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-08-02 10:08:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-08-02 10:08:34 [scrapy.middleware] INFO: Enabled item pipelines:
['fang.pipelines.MysqlTwistedPipline']
2019-08-02 10:08:34 [scrapy.core.engine] INFO: Spider opened
2019-08-02 10:08:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-08-02 10:09:33 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: fang)
2019-08-02 10:09:33 [scrapy.utils.log] INFO: Versions: lxml 3.7.2.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-10-10.0.17763-SP0
2019-08-02 10:09:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'fang', 'DOWNLOAD_DELAY': 0.1, 'DOWNLOAD_TIMEOUT': 10, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_FILE': 'NewHouse20190802.txt', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'fang.spiders', 'RETRY_TIMES': 3, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['fang.spiders']}
2019-08-02 10:09:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-08-02 10:09:33 [fang] INFO: Reading start URLs from redis key 'fangtianxia:start_urls' (batch size: 16, encoding: utf-8
2019-08-02 10:09:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'fang.middlewares.UserAgent',
 'fang.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-08-02 10:09:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-08-02 10:09:33 [scrapy.middleware] INFO: Enabled item pipelines:
['fang.pipelines.MysqlTwistedPipline']
2019-08-02 10:09:33 [scrapy.core.engine] INFO: Spider opened
2019-08-02 10:09:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-08-02 10:09:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://huangshan.newhouse.fang.com/house/s/b1saledate-b91/> (referer: None)
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\Desktop\FangTianxia_Redis\fang\spiders\fangtianxia.py", line 118, in parse_newhouse
    for i in range(1,int(last_page)+1):
ValueError: invalid literal for int() with base 10: 'b1saledate-7'
2019-08-02 10:10:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2019-08-02 10:11:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:12:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:13:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:14:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:15:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:16:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:17:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:18:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:19:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:20:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:21:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:22:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:23:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:24:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:25:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:26:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:27:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:28:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:29:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:30:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:31:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:32:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:33:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:34:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:35:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:36:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:37:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:38:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:39:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:40:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:41:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:42:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:42:45 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:42:45 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:42:49 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:42:54 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:42:59 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:43:04 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:43:09 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:43:14 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:43:19 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:43:24 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:43:29 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:43:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:43:34 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:43:39 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:43:44 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:43:49 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:43:54 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:43:59 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:44:04 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:44:53 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:45:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:46:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:47:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:48:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:49:40 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:49:40 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:49:40 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:49:44 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:49:49 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:49:54 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:49:59 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:50:04 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:50:09 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:50:14 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:50:19 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:50:24 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:50:29 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:50:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:50:34 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:50:39 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:50:44 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:50:49 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10065 connecting to 129.28.200.147:6379. 套接字操作尝试一个无法连接的主机。.

2019-08-02 10:51:38 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:52:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:53:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:54:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:55:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:56:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:57:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:58:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 10:59:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:00:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:01:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:02:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:03:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:04:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:05:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:06:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:07:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:08:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:09:32 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10051 connecting to 129.28.200.147:6379. 向一个无法连接的网络尝试了一个套接字操作。.

2019-08-02 11:09:32 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10051 connecting to 129.28.200.147:6379. 向一个无法连接的网络尝试了一个套接字操作。.

2019-08-02 11:09:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:09:34 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10051 connecting to 129.28.200.147:6379. 向一个无法连接的网络尝试了一个套接字操作。.

2019-08-02 11:09:39 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10051 connecting to 129.28.200.147:6379. 向一个无法连接的网络尝试了一个套接字操作。.

2019-08-02 11:09:44 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10051 connecting to 129.28.200.147:6379. 向一个无法连接的网络尝试了一个套接字操作。.

2019-08-02 11:09:49 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10051 connecting to 129.28.200.147:6379. 向一个无法连接的网络尝试了一个套接字操作。.

2019-08-02 11:09:54 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10051 connecting to 129.28.200.147:6379. 向一个无法连接的网络尝试了一个套接字操作。.

2019-08-02 11:09:59 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10051 connecting to 129.28.200.147:6379. 向一个无法连接的网络尝试了一个套接字操作。.

2019-08-02 11:10:04 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10051 connecting to 129.28.200.147:6379. 向一个无法连接的网络尝试了一个套接字操作。.

2019-08-02 11:10:09 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10051 connecting to 129.28.200.147:6379. 向一个无法连接的网络尝试了一个套接字操作。.

2019-08-02 11:10:14 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10051 connecting to 129.28.200.147:6379. 向一个无法连接的网络尝试了一个套接字操作。.

2019-08-02 11:10:19 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\commands\runspider.py", line 89, in run
    self.crawler_process.start()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\crawler.py", line 291, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1261, in run
    self.mainLoop()
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 1270, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "D:\Python3.6\Anaconda3\lib\site-packages\twisted\internet\base.py", line 896, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "D:\Python3.6\Anaconda3\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2894, in execute
    return execute(conn, stack, raise_on_error)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\client.py", line 2749, in _execute_transaction
    connection.send_packed_command(all_cmds)
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 585, in send_packed_command
    self.connect()
  File "D:\Python3.6\Anaconda3\lib\site-packages\redis\connection.py", line 489, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10051 connecting to 129.28.200.147:6379. 向一个无法连接的网络尝试了一个套接字操作。.

2019-08-02 11:10:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:21:21 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:21:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:22:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:23:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:24:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:25:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:26:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:27:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:28:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:29:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:30:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:31:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:32:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:33:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2019-08-02 11:34:34 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
